\chapter{Theoretical Framework}
\label{cha:theory}

This chapter establishes the theoretical foundation for the agent-orchestrated Retrieval-Augmented Generation (RAG) and Knowledge Graph architecture developed in this thesis. It begins by grounding the problem in the context of modern software development practices and quality assurance, followed by an in-depth exploration of Large Language Models (LLMs), RAG, and AI Agents, including their constituent components and operational mechanisms.

\section{Software Development Lifecycle \& Quality Assurance}
\label{sec:sdlc-qa}

Modern software development is characterized by rapid iteration and continuous delivery, largely facilitated by Continuous Integration and Continuous Deployment (CI/CD) pipelines. These methodologies accelerate feature delivery but place significant demands on quality assurance, particularly in ensuring the reliability of complex systems through effective testing.

\subsection{Continuous Integration and Continuous Deployment (CI/CD)}
\label{sec:cicd}
CI/CD represents a set of practices that enable rapid and reliable software releases \cite{humble2010continuous}. Continuous Integration involves frequently merging code changes into a central repository, followed by automated builds and tests. Continuous Deployment extends this by automatically deploying verified changes to production. While highly efficient, CI/CD necessitates robust testing strategies to prevent the introduction of defects at an accelerated pace.

\subsection{Regression Testing and Test Scope Analysis}
\label{sec:regression-test-scope}
Central to quality assurance in CI/CD environments is regression testing, which ensures that new code changes do not adversely affect existing functionalities \cite{rothermel1996analyzing}. However, re-running all tests for every small change is resource-intensive and impractical in large-scale systems \cite{yoo2012regression}. This gives rise to the critical challenge of \textit{test scope analysis}: the activity of intelligently determining the minimal set of legacy test cases relevant for verification when a new feature, change request, or defect fix is introduced. Effective test scope analysis balances the need for high test coverage with the efficiency of execution, preventing redundant tests while identifying potential gaps.

\subsection{Traceability in Software Engineering}
\label{sec:traceability}
Software traceability refers to the ability to link related artifacts throughout the software development lifecycle, such as requirements to design, design to code, and code to test cases. Robust traceability is fundamental for effective test scope analysis, as it provides the explicit connections necessary to understand the impact of changes and identify corresponding verification activities. However, maintaining accurate and comprehensive traceability in large, evolving systems is a significant challenge.

\subsection{Observability, Evaluation, and Deployment}
\label{sec:oevd}
Beyond the core development and testing activities, the successful operation of complex software systems, especially those incorporating AI, relies on robust practices for observability, evaluation, and deployment.
\begin{itemize}
    \item \textbf{Observability:} Refers to the ability to infer the internal states of a system by examining its external outputs \cite{beyer2016site}. In AI-driven systems, this is crucial for understanding how models and agents make decisions, identifying potential biases, and diagnosing issues in real-time.
    \item \textbf{Evaluation:} Encompasses the methods and metrics used to assess a system's performance, accuracy, and overall effectiveness. For test scope analysis systems, this includes quantitative metrics such as precision and recall, as well as qualitative assessments of practical utility and explainability.
    \item \textbf{Deployment:} Is the process of making the developed system available for use, ranging from local integration to large-scale production rollouts. For agentic systems, deployment strategies must consider integration with existing workflows, scalability, and maintenance.
\end{itemize}

\section{Large Language Models}\label{sec:llms}

Large Language Models (LLMs) form the cognitive backbone of modern AI-driven applications, including agentic systems. These models are advanced neural networks trained on vast datasets of text, enabling them to understand, generate, and process human language with remarkable fluency.

\subsection{Foundational Principles}
\label{sec:llm-principles}
At their core, LLMs are built upon the \textit{transformer architecture}, which allows them to process sequences of data in parallel, capturing long-range dependencies more effectively than previous architectures. However, the field is rapidly evolving beyond standard dense transformers. To improve efficiency and scalability, modern architectures often incorporate techniques like \textit{Mixture-of-Experts (MoE)}, where only a subset of parameters ("experts") are activated for a given input. This approach is explicitly utilized in open-weights models like DeepSeek-R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}. Other frontier models, such as Gemini 3 Pro \cite{gemini3pro_modelcard}, are explicitly built upon a sparse Mixture-of-Experts (MoE) transformer-based architecture, offering native multimodal support for text, vision, and audio inputs. Similarly, Claude 4.5 Sonnet \cite{claude_sonnet45_systemcard} exhibits advanced "hybrid" reasoning and multimodal capabilities, implying significant architectural innovations, though its specific internal structure remains proprietary.

Despite these structural variations, the primary training objective remains \textit{next-token prediction}: given a sequence of input tokens, the model learns to predict the most probable subsequent token. This simple task, when scaled across massive datasets and parameter counts, yields emergent capabilities in reasoning, coding, and general problem-solving \cite{brown2020gpt3, kaplan2020scaling}.

\subsection{Reasoning and Tool Use Capabilities}
\label{sec:llm-capabilities}
Beyond basic text generation, advanced LLMs exhibit significant capabilities relevant to agentic systems \cite{shen2024llmwithtools}:
\begin{itemize}
    \item \textbf{Reasoning:} LLMs can engage in various forms of reasoning, from simple fact retrieval to more complex logical deduction. Techniques like \textit{Chain-of-Thought (CoT)} prompting guide LLMs to break down complex problems into intermediate steps, making their reasoning process more transparent and accurate \cite{wei2022chainofthought}.
    \item \textbf{Tool Use:} A critical emergent capability is the ability of LLMs to interact with external tools or APIs. By learning to generate structured outputs (e.g., JSON function calls) in response to prompts, LLMs can extend their functionalities beyond their training data, enabling them to perform calculations, query databases, or access real-time information.
\end{itemize}



\section{Retrieval-Augmented Generation}\label{sec:rag}

Retrieval-Augmented Generation (RAG) is a powerful technique that enhances the capabilities of LLMs by enabling them to fetch and incorporate relevant information from external knowledge sources during the generation process \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. This mitigates issues like \textit{hallucinations} (generative errors where the model invents facts) and improves precision by grounding the LLM's responses in factual, up-to-date data, although it introduces the risk of retrieval errors (fetching irrelevant context). In the context of test scope analysis, RAG serves as the bridge between the static knowledge contained in software artifacts (code, requirements, tests) and the dynamic reasoning capabilities of the LLM.

\subsection{Embeddings and Semantic Search}
\label{sec:embeddings}
The core mechanism enabling RAG is the concept of \textit{embeddings}. Embeddings are numerical representations (vectors) of text, code, or other data, where semantically similar items are mapped closer to each other in a high-dimensional vector space \cite{mikolov2013efficient}. This allows for efficient comparison and retrieval of semantically related information, surpassing keyword-based search by capturing intent and context.

For technical domains, generic language models often fail to capture the semantic nuance of code or specialized terminology. Therefore, the choice of embedding model is critical. While seminal work like BERT \cite{devlin2019bert} and Sentence-BERT \cite{reimers2019sentence} laid the foundation for contextual embeddings, the field has evolved towards massive general-purpose models. Currently, flagship proprietary models such as OpenAI's \texttt{text-embedding-3} \cite{openai_embeddings_docs} and Google's \texttt{gemini-embedding-001} \cite{lee2025geminiembeddinggeneralizableembeddings} offer state-of-the-art performance. However, in sensitive software engineering contexts where data privacy is paramount, high-performing open-weight models are often preferred as they allow for secure, on-premise deployment. Notable examples include Qwen3-Embedding-8B \cite{zhang2025qwen3embeddingadvancingtext} and BGE-M3 \cite{chen2024bgem3embeddingmultilingualmultifunctionality}, which provide comparable retrieval quality while maintaining data sovereignty.

\subsection{The RAG Pipeline Components}
\label{sec:rag-pipeline}
An effective RAG system for software engineering comprises several specialized components working in concert to ingest, process, and store data:

\subsubsection{Document Loaders (Data Integration)}
Document loaders are responsible for ingesting data from diverse software development lifecycle (SDLC) sources \cite{gao2023retrieval}. In a corporate environment, this requires "connectors" capable of interfacing with:
\begin{itemize}
    \item \textbf{Version Control Systems:} Ingesting raw source code and commit history (e.g., Git).
    \item \textbf{Documentation Platforms:} Parsing structured specifications (e.g., Markdown, PDF, Internal Wikis).
    \item \textbf{Issue Trackers:} Extracting bug reports, user stories, and acceptance criteria (e.g., Jira, Linear).
\end{itemize}
These loaders normalize disparate data formats into a unified document structure suitable for processing.

\subsubsection{Text Splitters (Semantic Chunking)}
Standard text splitting (e.g., every 500 characters) is detrimental in software contexts where maintaining logical integrity is paramount, especially given the "lost-in-the-middle" phenomenon where LLMs struggle to recall information from the center of long contexts \cite{liu2023lost}. Instead, \textit{structure-aware splitting} strategies are employed:
\begin{itemize}
    \item \textbf{Code-Aware Splitting:} Parsing the Abstract Syntax Tree (AST) of source code to split based on functional boundaries (classes, methods, functions) rather than arbitrary line counts.
    \item \textbf{Header-Based Splitting:} processing requirements documents by hierarchy (e.g., Section 1.2, 1.2.1), ensuring that the parent context (headers) is preserved with each child chunk.
\end{itemize}

\subsubsection{Knowledge Stores (Graph-Vector Hybrid)}
To effectively map the test scope, the storage layer must capture both the \textit{semantics} (meaning) and the \textit{structure} (dependencies) of the data.
\begin{itemize}
    \item \textbf{Vector Indices:} Store the high-dimensional embeddings, enabling efficient similarity search (e.g., "Find tests related to authentication failures") \cite{johnson2017billion}.
    \item \textbf{Knowledge Graphs (KGs):} Explicitly model the relationships between entities (e.g., \texttt{Requirement-A} $\xrightarrow{verifies}$ \texttt{Test-B} $\xrightarrow{covers}$ \texttt{Function-C}) \cite{pan2024unifying}.
    \item \textbf{GraphRAG:} A hybrid approach where vector embeddings are stored as properties within the nodes of a Knowledge Graph \cite{edge2025localglobalgraphrag}. This allows for powerful composite queries: "Find all test cases that verify requirements semantically similar to 'Login Security' AND are linked to the 'AuthService' module."
\end{itemize}

\section{AI Agents}\label{sec:ai-agents}

AI Agents represent a paradigm shift from simple LLM interactions to autonomous, goal-oriented systems. An AI Agent can be conceptualized as an \textbf{LLM equipped with Memory, Tools, Reasoning, and Planning capabilities}. This architecture enables agents to break down complex tasks, interact with their environment, and learn from feedback.

\subsection{Key Components of an AI Agent}
\label{sec:agent-components}
\begin{itemize}
    \item \textbf{LLM Integration:} The Large Language Model serves as the agent's brain, interpreting inputs, generating thoughts and plans, and deciding on actions. It translates high-level goals into executable steps and understands the outputs from tools.
    \item \textbf{Memory Systems:} Agents require both short-term and long-term memory to maintain context and accumulate knowledge.
    \begin{itemize}
        \item \textbf{Internal State/Short-Term Memory:} This includes the current conversational context, scratchpad for intermediate thoughts, and temporary variables. Strategies like \textit{Compaction} are used here to prevent context rot \cite{anthropic2025context}.
        \item \textbf{External/Long-Term Memory (The "Playbook"):} Rather than a static database, long-term memory in advanced agents acts as a "curated playbook" \cite{zhang2025agenticcontextengineeringevolving}. The agent actively synthesizes lessons from past interactions, storing refined strategies and domain facts in the RAG system (Knowledge Graph), enabling it to improve over time without retraining.
    \end{itemize}
    \item \textbf{Tools:} Tools are external functions, APIs, or scripts that an agent can invoke to interact with its environment, perform specific operations (e.g., search a database, execute code, call a RAG pipeline), or gather information.
    \item \textbf{Reasoning and Planning:} Agents possess mechanisms to plan a sequence of actions to achieve a goal. The foundational paradigm is the \textit{ReAct} (Reason+Act) framework \cite{yao2023reactsynergizingreasoningacting}, which enables LLMs to interleave reasoning traces ("Thoughts") with task-specific "Actions" and "Observations."
    \begin{enumerate}
        \item \textbf{ReAct Loop:} The agent generates a thought (e.g., "I need to check the database"), executes an action (calls the search tool), and observes the output, repeating this cycle until the task is done.
        \item \textbf{The ACE Cycle (Advanced):} Building on this, advanced systems employ the ACE cycle \cite{zhang2025agenticcontextengineeringevolving} for self-improvement: \textit{Generation} (of the plan), \textit{Reflection} (critiquing the plan/result), and \textit{Curation} (saving the lesson to memory).
    \end{enumerate}
    \item \textbf{Guardrails:} These are mechanisms implemented to ensure agents operate safely, reliably, and within defined ethical and operational boundaries. In the context of this thesis and deployment within a corporate environment like Ericsson, guardrails are critical for protecting proprietary intellectual property and ensuring operational integrity. They can be implemented using two complementary approaches:
    \begin{itemize}
        \item \textbf{Deterministic Guardrails:} Use rule-based logic to enforce strict compliance \cite{langchain2025guardrails}. For test scope analysis, this includes verifying that suggested test files actually exist in the repository before recommendation, or enforcing the redaction of Personally Identifiable Information (PII), such as masking sensitive user IDs in bug reports, before they are processed by the model.
        \item \textbf{Model-based Guardrails:} Utilize LLMs to evaluate the semantic quality of inputs and outputs. Techniques such as \textit{Constitutional AI} \cite{bai2022constitutionalaiharmlessnessai} use AI feedback to align models with safety principles, while specialized models like \textit{Llama Guard} \cite{inan2023llamaguardllmbasedinputoutput} classify content risks. In this system, model-based guardrails validate the reasoning behind test scope recommendations, ensuring the agent does not hallucinate connections between unrelated code modules.
    \end{itemize}
    Additionally, \textit{Human-in-the-loop (HITL)} mechanisms provide a critical layer of oversight for high-stakes actions, consistent with the interactive machine learning principles outlined by Amershi et al. \cite{Amershi_Cakmak_Knox_Kulesza_2014}. This architectural pattern involves pausing the agent's execution flow (interrupts) when a sensitive action is proposed. The system's state is persisted, allowing a human expert to review the request and exercise supervisory control by either \textit{approving} the action, \textit{editing} the parameters (e.g., refining a generated test case), or \textit{rejecting} the proposal entirely with feedback.
\end{itemize}

\subsection{Context Engineering}
\label{sec:context-engineering}
Effective RAG and Agentic systems are not merely about retrieving data, but about \textit{adapting} it to maximize the LLM's reasoning capabilities. Context Engineering represents a systematic framework for this adaptation, treating context not as a static buffer but as an evolving playbook for the agent. It is distinct from \textit{Prompt Engineering}, which focuses on optimizing the instructions given to the model. Context Engineering, conversely, focuses on the architecture and state management of the information (context window) supplied to the model to support complex reasoning tasks \cite{anthropic2025context, zhang2025agenticcontextengineeringevolving}.

\subsubsection{The Challenge of Context Rot}
As systems scale, simply retrieving more data leads to "Context Rot," a phenomenon where the model's ability to recall and reason about specific information degrades as the context window fills with distractors \cite{anthropic2025context}. This aligns with the concept of "Brevity Bias," where critical domain insights are lost amidst noise \cite{zhang2025agenticcontextengineeringevolving}. Therefore, treating context as a finite, high-value resource is essential.

\subsubsection{The ACE Framework}
To address these limitations, we adopt principles from the Agentic Context Engineering (ACE) framework \cite{zhang2025agenticcontextengineeringevolving}. ACE treats context construction as a modular process involving:
\begin{itemize}
    \item \textbf{Generation:} Retrieving and drafting initial context blocks based on the query.
    \item \textbf{Reflection:} Analyzing the retrieved data to identify gaps or inconsistencies.
    \item \textbf{Curation:} Iteratively refining and structuring the context to create a coherent narrative or "playbook" for the agent.
\end{itemize}

\subsubsection{Optimization Strategies}
Practical implementation relies on specific strategies to combat rot and maintain long-horizon coherence \cite{anthropic2025context}:
\begin{itemize}
    \item \textbf{Compaction:} Periodically summarizing conversation history or verbose tool outputs to retain only the essential state changes, freeing up tokens for new reasoning.
    \item \textbf{Structured Note-Taking:} Empowering the agent to explicitly "write down" key facts or decisions into a dedicated memory block (or Knowledge Graph), rather than relying on implicit recall from a long transcript.
    \item \textbf{Delimited Evidence:} Using clear XML-style tags (e.g., \texttt{<code\_snippet>}) to demarcate external data from internal logic, preventing the model from confusing retrieved evidence with system instructions.
\end{itemize}

\section{Knowledge Graphs in Software Engineering}
\label{sec:knowledge-graphs}

Knowledge Graphs (KGs) provide a structured way to represent complex, interconnected data, making them particularly suitable for modeling the dependencies in software systems \cite{pan2024unifying, kesri2021autokg}. Unlike vector stores, which capture semantic similarity, KGs capture explicit structural relationships.

\subsection{Graph Data Models: RDF vs. LPG}
\label{sec:rdf-vs-lpg}
Two primary data models exist for implementing Knowledge Graphs:
\begin{itemize}
    \item \textbf{Resource Description Framework (RDF):} A W3C standard based on triples (Subject, Predicate, Object). RDF is ideal for semantic web applications and interoperability but can be verbose for traversing complex property-rich graphs typical in software engineering.
    \item \textbf{Labeled Property Graphs (LPG):} Used by graph databases like Neo4j, LPGs allow nodes and relationships to have internal properties (key-value pairs). This model is often preferred in industry for software analytics because it allows for efficient storage of metadata (e.g., a "calls" relationship can have properties like \texttt{frequency} or \texttt{latency}). This thesis utilizes the LPG model to support the rich metadata requirements of test artifacts \cite{edge2025localglobalgraphrag}.
\end{itemize}

\subsection{Ontologies in Software Engineering}
\label{sec:ontologies}
An \textit{ontology} defines the schema or the "mental model" of the domain. In software engineering KGs, the ontology dictates the types of entities (e.g., \texttt{Class}, \texttt{Method}, \texttt{TestCase}, \texttt{Requirement}) and the allowed relationships between them (e.g., \texttt{inherits\_from}, \texttt{verifies}, \texttt{traces\_to}). A well-defined ontology is crucial for traversing the "semantic gap," allowing an agent to reason that if a \texttt{Requirement} is changed, the \texttt{TestCases} that \texttt{verify} it are candidates for regression testing \cite{antoniol2025recovering, radhakrishnan2023create}.

\section{Evaluation Metrics}
\label{sec:evaluation-metrics}

To rigorously assess the performance of the proposed retrieval system, standard metrics from the field of Information Retrieval (IR) are employed. The primary goal in test scope analysis is to present relevant tests to the engineer (high recall) while minimizing the noise of irrelevant results (high precision) within the limited window of user attention \cite{manning2008introduction}.

\subsection{Rank-Aware Metrics}
\label{sec:rank-aware-metrics}
Since the system provides a recommended list of tests, the order of results is critical. A relevant test appearing at position 50 is effectively "missed" by a busy engineer. Therefore, we focus on rank-aware metrics:

\begin{itemize}
    \item \textbf{Recall@k:} Measures the proportion of relevant items retrieved within the top $k$ results (e.g., $k=10$). This is the primary safety metric, indicating the system's ability to surface correct tests within the user's immediate view.
    \item \textbf{Precision@k:} Measures the proportion of items in the top $k$ results that are actually relevant. High precision@k ensures that the user does not waste time reviewing irrelevant suggestions.
    \item \textbf{Mean Average Precision (MAP):} While Recall@k focuses on a specific cutoff, MAP provides a single-figure measure of quality across recall levels. It calculates the average precision at the position of every relevant item, rewarding systems that place relevant tests higher in the list. This metric is widely regarded as the standard for evaluating ranked retrieval systems \cite{manning2008introduction}.
\end{itemize}